Linux is case sensitive language
RHCSA - EX200
RHEL8 			vs		RHEL7
released 2019				2014
XFS					XFS
max XFS size 1024 TiB			max XFS size 512 TiB
max RAM supports 24TiB			max RAM supports 12TiB
supports podman for containarizaton	by default supports docker


Linux			vs		Unix
Linus dev from Linux			denies richie and ken thomsan
dev by modifying unix kernal		dev from scratch for motorola, HP etc
					was not possible to use at home due to high memory and RAM size
flavor:					linux, MacOS, SunSolaris etc derived from Unix
fedora: Redhat and CentOS(free)
debian: ubunto and MintOS, Kali

Highly secured + multiple layer of security + stable + supports previous hardware version + does not run virus +
supports all file system + Open source + used from smart watch to super computer.

cat /etc/redhat-release

~ - shows home directory
#: root user
$: shows normal user
pwd - shows present working dir
ls -alh -> shows .(current dir) and ..(parent dir) + so cd .. -- will move you to parent dir    h-option shows size in human redable format like kb,mb,gb etc instead of bytes
ls -d : list all sub-directories

<permision> <link> <user> <group> <size> <DATE and TIME modified><File>
user permissions first char shows d<dir> or -<normal file> or s<socket file> or l<link> etc
second 3 chars shows <owner> permission
next 3 char shows <group> permisison 
next 3 shows <other>
example: dr-xr-xr-x 		read-4 write-2 execute-1

mkdir -p -> -p options used to create parent child dir
rm command always comes with promt + alias command shows linux commands with promt for exmaple: alias rm ---> shows rm='rm -i' here -i asks for input
if you dont want command to promt then unalias <command name>

sftp is used same as scp but secured one. sftp username@server --> change dir to file location --> mget filename (to download file) or we can use ? to see sftp options


Day1-7:
touch: command used to create empty file + manipulate file timestamp (touch -t yymmddhhmm(custom date which you want) <filename>)
more: will show file content per page and press v to enter in vi mode. 
file <filename> : cat command can't open binary files so use file command to check type of file. 
strings <binary filename>: to cat binary file

Day8: shell expansion: shell checks the command + manipulate it and then pass it to kernal
'': echo as it is
"": echo value written inside ""
<<: use as custom marker: to come out of file while writing. example: cat > hello.txt <<stop --> if i write hello,hi,stop  then will come out of cat command. and hello.txt file will only have <hello,hi,>


control operator: used to execute multiple commands 
; : used to execute mutiple commnads serially one after other. example: date;cal;echo $SHELL
& : execute cmnds parallely (execute cmnd in background)
? : its variable which stores result of last command.  stores value = 0 if last cmnd success else any random value
&& : logical AND
||: logical OR
#: shell ignores the cmmands written after #
\ : whatever operator you give post \, shell will ignore that. 


shell variables:
1. system defined var:capital letters defined by Developers. (SHELL,PWD,HOSTNAME,USER etc) 
2. user defined var: user defined. 
If you want to permanently use env variables then define in .bashrc file 

set: shows env varibales in system
unset <var> : to unset env variable
echo $PS1 : PS1 is shell env variable shows how the perticular shell prompt looks like. [sh shell shows [u@host tild]# or $]. we can change shell prompt using PS1 variable
like PS1 = 'Hello Shantayya' then aftr logging to shell you will see [hello Shantayya]:cursor
PATH: var used by shell to check where the camnds binaries are. 
SHLVL: used to see level of shell. [example: if you executed zsh inside bash shell then you will on 2nd level] we can use shell inside shell
env -i: used to ignore env variables exported by user.

Shell embadding, history and options:
`` backticks: works as $()
!!: bang sign to execute last command
history -c: to clear history + we can repeat perticular command with !<number from hitory> + HISTSIZE stores how many commands history can store + >.bash_history to perpanently clear history
export HISTTIMEFORMAT='%d %m %y %T': used to set date and time for history commands + history -d <line number> : to delete perticular history command
space cmnd: comands does not goto history but works only in debian os.

File Globbing: used to dynamically generate file names: [ex: ls *file*]
? - one char
+ - one or more char
* - zero or more char
[] - char between []
[!]- no char between[]
use LANG=C env var to see case sansitive output if ls [A-Z]ile command shows output having small letter file,file123 etc

Day13: Input and output redirection 
stdin (signal 0): standered input through whch we send input to shell (keyboard)
stdout(1>): through which shell transfer output to user (display/file). cmand > output.txt
stderr(2>): error output (display/file)		cmnd 2>error.txt

noclobber: avoid to overrite file using (set -o noclobber --> it will add C in noclobber output). if you try to overrite existing file, it throws error.
forcefully overrite: then use commnd >| filename
(output redirection) 2>&1 : if we are not sure cmnd gives output or error then we use 2>&1 to redirect out+error in single file. 
/dev/null 2>&1: used to stop cluttering (show output on screen) then we redirect output to blackhole. yum install -y httpd >/dev/null 2>&1 + >filename: used to nullify
(input redirection) <: example: cat <filename    


Day14: Filters used in Linux
commands which are used with | called filters. 
tac filename: used to reverse content. (tee also worls like cat)
grep: used to search perticular string in files. -i: ignore case -v: except string  -A1/2/3: lines after string  -B1/2/3: print lines before string  -w if want to fetch one result out of many given results.

passwd file has 7 columns: <user><encryption passwd><user id><grp id><user display name><home dir><default shell>

cut: used to show columns from result. -d:delimiter -f:fields -c:char
ex: cut -d: -f1,3 /etc/passwd 

tr: used to translate content   (ex: cat say.txt | tr 's' 'S' --> it will translate all small s to S)
wc: -l:line -w:words -c:char
sort: as name suggest   -k1/2/3: 1st/2nd/3rd col (ex: sort -k2 say.txt)
uniq: use with sort -c: used to count occurenece of words
comm: used to see multiple files common entries together. (ex: comm file1 file2)
sed: used to manipulate file content -i:change in file directly, d: delete line with string  s: change old to new string (ex: sed 's/old/new/' or sed '/string/d')

time cmnd: used to check how much time taken by command to execute
tar tvf: used to see files inside tar           c:create v:verbose p:prserve permission x:untar f:file z:gz ext

find <location>  -type f/d -perm <perm to search on /a:r/w/x> -iname <filename> -empty<to see empty files> -user<serach with owner> -group -mtime <+/-days> -mmin <+/- min> -atime<access time in days> -size<+/- M/G>
if we have to execute other operation after search the use -exec cmnd {} \;  (ex: find . -type f -perm 0777 -print -exec chmod 0555 {} \;)

locate: very powerful command to search faster. <use updatedb command to update index>

Day16: reguler expression
BRE: basic regex-> use -G with grep	--> grep -G 's\|ya' say.txt        ya$--> end of string with ya 	^ya--> starts with
ERE: extended regex --> use -E with grep  --> ex: grep -E 's|ya' say.txt
PRCE: perl regex --> use -P with grep

\bstring\b or -w: search with space before and after


Day17: stream editor
sed: used to manipulate file content 
-i:change in file directly, d: delete line with string  s: change old to new string (ex: sed 's/old/new/' or sed '/string/d') 
echo Sunday | sed 's_\(Sun\)_1ny_' --> it will replace Sun with Sunny--> Sunnyday
echo 2014-10-01 \; if we need to replace - with + then: echo 2014-10-01 | sed 's/\(....\)-\(..\)-\(..\)/\1+\2+\3/' 
cat filename | sed 's/o\{2,3\}/A/' --> it will replace oo or ooo with A



Day18: Introduction to vi editor
vi: is old editor however vim provides extra features with lot of flexibility. its modified vi editor. 
1. command mode -> default mode, press escape (create,open etc)
2. insert mode: when we need to edit file. press -> insert key 
aAiIoO: these will work in command mode 
i: start writing from current char	I: start writing from start of current line
a: aftr current char	A: end of current line
o: after current line	O: before current line
x: delete current char   X: delete previous char
u : undo changes	.: redo changes
r <new char>: to replace current char with new one
p: paste after current line 	P: paste before current line		dd: cut current line	yy: copy current line 
to copy or cut multiple lines use number and dd or yy then use p or P
$: to jump to last char of line		0: to jump to start of line		d$: delete current char to last char of line.	d0: delete current char to start char of line
G: starting page 	gg: last line of page
J: to merge previous and current line,<cursor should be at start position before pressing J)
ddp: swicth current and next line
w: word by word next jump	b: backward word to word jump		dw: delete word
/string: forward search		?string: backward search

:r cmdn or filename: used to add comamd result or new file content in current file

buffers: in vi editor 36 types of buffers are being used. 
"add: to cut current line and add to buffer		"ap: paste buffered line

vim file1 file2 file3: To modify multiple files	:args to see which file we are updating		:n to move to next file		:rew to move back to previous file
:e toggle to previous edited file

:set number or se nu --> shows line numbers	create .vimrc file with set number options to open all file with line number 

vimtutor: very powerful tool to learn vim editor.
copy only saves last copied line where as in buffere we can save upto 36 copies. 



Day19: Local user management   [user entry get added to /etc/shadow, /etc/group /etc/passwd file]
who: whoever has logged in to machine
w: whoever is executing what command and when logged in to machine
id: shows user id
su user: switching to user account temporarely (pretending to be user). it will not take you to home directory. 		
su - user: completely switch to user account with pwd as home dir. using env variables of that user. 

sudo: super user do
visudo : when one update [user	ALL:ALL		NOPASSWD: ALL] then perticular user perform all commands without any password promt. if we passwd promt then remove NOPASSWD from line.
user	ALL:ALL		NOPASSWD: ALL, !/usr/sbin/useradd	[limit command execution: user cann't execute useradd command]	
if we dont want to limit admin permisions user wise, we can put all users in group and update sudoer permission for that group.

0(root)-1000: id are preserve for system. linux allocated user id after 1000 to normal users.
passwd file has 7 columns: <user><encryption passwd stored in /etc/shadow file><user id><grp id><user display name or desciption><home dir><default shell>
<default shell>: we can define /sbin/nologin/ to make the account as service acocunt so user can't login

ideal way to add user: useradd -m <modify> -d <home dir default perm 700> -c <display name> username
Here we have created user with only homedir + display name but /etc/passwd contains default shell,uid,gid etc so that information stored in /etc/default/useradd or useradd -D to check default entries
we can modify these setting

userdel -r username: -r deletes home dir as well
usermod -s <shell>: we can modify default shell
chsh -l: shows shell available in system
chown user:group dir: to change dir ownership		chmod 700 dir

/etc/skel: this is very important dir which contains profile files. and whenever new user is created then these files are copied to new user home dir.
you can push new features to new user accounts through this dir files.



Day20: password management    Note: linux uses crypt function at backgnd for passwrd encryption
sudo su -: if user entry is there in sudoer file but you dont know root passwrd then also you can su to root using. if promt for passwd provide user passwrd.
passwd user: root to reset user passwd for user.

password related settings contained in /etc/shadow/:
/etc/shadow: file contains <user> <encrypted passwd> <no.of days since pass not chnaged calculate from 1Jan1970> <after how many days passwd shld chnaged><passwd expiry days> <warning to be thrown no of days before expry> <disable no. of days>
/etc/login.defs: contains default password settings (min_pass_days,max_pass_days,warn_pass_days etc) related info. admin can chnage these setting so that it will apply to all the users. 

chage username: to modify default passwd setting for perticular user. 
chage -l username: to list paswd settings for perticuler user. 

openssl passwd <password>: it will give diff encryp pass all the time. we can use -salt datastring to define paswd . openssl passwd -salt <number> <password>

useradd -m -p $(openssl passwd <password>) username --> it will create user with encrypted passwd. but issue with this command is password will appear in history.
lock user: usermod -L username	(this will add ! in /etc/shadow) 	or 	passwd -l username (this will add !! in /etc/shadow)
unlock user: usermod -U username 	or 	passwd -u username


Day21: profile files
1. system profile files: works globally : each shell (bash/ksh) source profile setting(PATH, PS1,HOSTNAME, execute /etc/inputrc(keyboard flags), /etc/bashrc etc) from /etc/profile to current env or you can put file in /etc/profile.d directory
2. user profile files: works for perticular user

.bash_profile: used to add $HOME to PATH and source .bashrc file + this file loads at every login. 
.bashrc : executes this file at every shell open + source global /etc/bashrc file + user spefic functions and env vars to save permanetly
.bash_logout: tells system that user has logged out. 



Day22: Group management 
if want to provide permisisons on mass level then create group and add all users to that group, provide reqrd permsision to group.

primary group: whenever user added to system at the same time same name group is also created. each user is part of its primary group. /etc/group 
secondary group: groups apart from primary are called secondary 

groups: shows user is part of which groups
usermod -a<append> -g<add primary gr> -G<add secondry grp> UNIX<group name> unix<usr name>: add group to existing user
vi /etc/group 			: 		add user with , separated to existing group.
groupmod -n <new name> <old name>: 		change existing group name.
groupdel grpname		: 		delet grp but it should not be primary
gpasswd -A <username> <grpname>	: 		To make user as Admin of the group  --> gpasswd -a <usrname> <grpname> : Admin can add user to group 
Note: its not necessary that admin to be a part of group. 

gpasswd -d <username> <grpname> : 		delete user from grp
gpasswd -A "" <grpname> 	: 		to dismiss all admins from group



Day23: File security in Lunux
File security is managed through 
1. standard permissons
2. advanced permissions

ls -lih --> 
<inode> <file type + permisison of file on own,grp,othr,SGID or SUID  + sticky bit + ACL symbol> <links> <owner> <grp> <size> <date> <file>
file permission:
1. char represent type of file (d:dir,-:normal file,l:links b:block s:socket etc)
2. next 9 char shows owner,group and other permissions

r: 4	w: 2	x: 1 --> total 7(Full perm)	0(no perm)

Schenario1: Shantayya wants read access on file1
solution: 
1. change onwer to shantayya if file1 only read by him. 	[chown <onwer> filename]	or [chgrp <grpname> filename]
2. add him to group and assign necessary perm on group		[chmod 600 filename]
3. provide perm to others so he can read. but here other users also read then which is security breach		[chmod 666 filename]

If we want to remove execute permission from user,group and other then
chmod u-x filename; chmod g-x filename; chmod o-x filename;				Note: use u+x,g+x,o+x to add execute permission to user,grp and others 

Note: based on the umask 4 digit number default permissions are assigned to new created files. (umask :  to see what number is defined for umask)
1st digit: advance perm		2nd: user	3rd: group		4th: other
umask number is defined in profile files. 
max default permission on any file=666<user><grp><other>		--> system does not give default execute perm due to security.
(max perm)  - UMASK  = effective permission on new files
  666	    - 022    = 644 (rw-r--r--)

max default permission on any directory = 777<user><grp><other>		--> without execute permission user can't access dir + make sure with execute we give read access otherwise its of no use. 
(max perm)  - UMASK  = effective permission on new directories
  777	    - 022    = 755 (rwx-r-xr-x)

mkdir -m <perm> dirname 	 	: used to create dir with permission. 
cp -rp <dir or file> <destination>	: preserve permisisons while copying

Note: even if script does not have execute perm then one can run using sh shell. ideally we should use ./ beacuse script written using bash shell.


Day24: advanced file security
umask -S		: shows perm symbolically
umask -S u=rwx,go=	: set umask perm symbolically

sticky bit: shows that user can only delete files owned by him in directory.  
chmod +t dirname	: to apply sticky bit		or append 1 while executing chmod --> chmod 1777 <dirname>
chmod -t dirname	: to remove stiky bit

If other user has execute permisison then sticky bit will be t (small case) otherwise T

SGID	: set group id bit --> shows group of all files under dir is same group of that dir when we create any new file. we append 2 while applying perm on dir 
chmod 2777 dirname  or chmod g+s dirname	: to apply SGID bit
chmod 777 dirname  or chmod g-s dirname		: to remove SGID bit

SUID	: set user id bit	--> It executes any file as its owner or root is executing. 
chmod 4777 filename  or chmod u+s filename	: to apply SUID bit
chmod 00777 filename  or chmod u-s filename  	: to remove SUID bit

Note: even if we read special and advanced permissions but these are not enough in situations where diff users need dif permissions. ther we use access control list.


Day25: Access control list (shows + at the end of permissions otherwise shows .)
cat /etc/fstab		: defaults shows that fs supports ACL.
getfacl filename	: shows permissions available on file
setfacl -m --no-mask u:<usernam>:<perm>	filename	: provid acl permission to user on file		if dont want to update effective mask value then use --no-mask in command
setfacl -m g:<grpname>:<perm>	filename	: provide acl perm on group
setfacl -b filename				: remove acl from file
setfacl -x g:<grpname> <filename>		: top remove acl from group
Note: mask value is any max perm assigned 


Day26: Inodes,Hard and soft links 
Note: RHL8 xfs dont have option to disable acl. this option was there in ext4 fs.
Inode		: ds which stores file metadata except file name and content.
hard link	: ln link_name	filename	+create separate file with same content 	+link no increases	+deleting orig file has no impact on hard link
soft link	: ln -s link_name file		+create shortcut				+link increases		+deleing orig file makes file not accessible


Day27: Process Management
Process: a compiled source or prgm running in system. each process has unique ID.
Parent process ID: always less than child ID.
system always start init(earlier linux versions) or systemd(latest versions) process(ID is 1) in booting process. 
daemon: system processes starts their own and keep running till the end. (Never die) 
Zombie: process killed but stil shown in system. (they don't use resources just available in process entry table)

jobs			: command list all jobs running in bg or foregrnd. 
echo $$	or ps -C bash	or pidof shell	: shows current shell PID
echo $PPID		: shows current shell parents PID 
 
fork		: splitting the process into child and executing its copy. exmaple: I am on bash --> ksh starts child process --> exec bash --> use same PID and PPID
ps fx	or ps -ef		: shows process detailed info	
<PID><TTY<STAT><TIME<CMND>
STAT	: shows the current status of process
D	: uninterruptible sleep (usually IO)
R	: running
S	: interruptible sleep(waiting for an event to complete)
T	: stopped (either by job signal or bcz its being traced)
X	: dead (should never be seen)
Z	: defunct(zobie) process. terminated but not reaped by parents. 
I	: idle state
Along with above stat keywards, below symbols also shown,
<	: high prioriy
N	: low priority
L	: has pages locked in memory
s	: session leader
l	: multithreaded process	
+	: foreground process
CMND	: which command has started this process.

pstree -p : shows process tree with its PID
pstree -p -u <username>	: shows processes ran by perticular user.

kill PID	: kills [-15 default] process. kill command has approx. 64 types of signal.(kill -l shows signal list)
SIGHUP -1	: to reread the configuration (kill -1 1 asking systemd process to reread its configuration)
SIGKILL -9	: asking kernal to kill it. In std kill command signal sent to process to kill but when we use -9 signal sent to kernal to kill process. Sure kill. 
SIGSTOP -19	: to stop process
SIGCONT	-18	: to resume the process (kill -18 PID)

pkill name	: we can stop multiple processes started with perticular name (ex: pkill sleep)
jobs
fg <jobs no.>		: to bring the bgrnd process in frground.


Day28	: Top command
<uptime> <no. of users logged in> <load average 1min:5min:15min>
<total tasks:	running,	stopped,	zombie>			Note: processes are divided into multiple tasks.
<%CPU	:	time spent by cpu in user space,	system space(kernal),idle state,handling hrdwr intrpts,soft intrpts,in serving other vms -steal time >
Mib MEM	:	total,	free,	used,	buffer(writing)/cache(reading)
Mib Swap:	total,	free,	used,	available	Note: swap is virtual memery used by CPU beyond RAM memory. idealy same size of RAM,doubled of RAM
<PID>	<USER>	<PR>	<NI>	<VIRT>	<RES>	<SHR>	<%CPU>	<%MEM>	<TIME>	<CMND>
PR	: priority value of process. higher the value-less priority and vice versa. always +20 of NI
NI	: nice value. used to modify process priority value. 
VIRT	: total memory consumed by process
RES	: memory consumed by process in RAM	(%MEM is % of RES)
SHR	: amount of memory shared with other processes. 

Keys:
press K	and PID to kill process
M	: to sort the process acording to mem use
P	: CPU wise
N	: process ID wise
T	: time wise
u	: user wise

process priority and Nice value:
process priority(total 139)	: used by kernal to schedule a task.
Nice value: these are user space values used to control process priority values. 
-20(Highest priority) to +19(lowest)		Note: only root user can assign minus nice values

priority wise max cpu time is allocated to processes. process priority = nice value + 20
0-99 are used by kernal and 100-139 used by user

nice -n	num	cmand					: for new process
renice -n(new priority) <nice value range> <PID>	: for existing process



Day29: Disk Management
lsblk 	: list the block devices in system		--> lsblk -f: shows list of block devices with fs type
fdisk -l : shows detailed infor about devices + also used to create partitions (max 4)
dmesg	: gives block devices booting logs captured at the time of booting

1. How to erase perticular disk permanantly:
badblocks -ws /dev/sda or sdb <device path>	: -w(write mode test)	-s:shows % completion this command delete each secter 4 times and push random data.
or 
dd if=/dev/zero of=/dev/sda  	: makes each sector or block zero 


2. Adding block devices(SCSI(sda/sdb),SATA etc) on the go except nvme(cannot added on the go) dick type:
ls /sys/class/scsi_host/ | while read host; | do echo  "- - -" > /sys/class/scsi_host/$host/scan ; done
or 
for x in `/sys/class/scsi_host/` ; do echo "------$x scanned----" echo "---" > /sys/class/scsi_host/$x/scan/ ; done

fdisk -l <block device name>		
Note: fdisk --> partition MBR disk= max 4 primary partitions or 3 parimary,1 extended partn -> its primary partitn where further logical partitions(max 5) can be created.
parimary partitions: partitions where we can keep os + other files
gdisk --> pertition GPT disk =max 128 partitions

parted command can be used to partition MBR or GPT disk.
cat /proc/partitions --> contains partition information.

fdisk /dev/sda --> if you press m then helps you to create parition based on options
n --> p(primary or e-extended)--> 1(1-4 partitions) --> 2048 (default sector)-->+1G (last sector i.e size) -->enter
if you want to chnage partition type then press t ---> to change partition type L --> select (8e for LVM type) --> w (save changes) --> enter

parprobe /dev/sda or only partprobe --> let kernal read the partition changes
lsblk 	--> to see partition created	(MAJ--> disk type number SCSI(8) nvme(259) MIN--> its partition no. 1/2/3 etc)


3. creating directory to assign to partition:
mkdir /data

4. mount /dev/sda1 /data --> will throw error bcz system dont know what fs type /data is using so before this we need to (format partition)create fs type being used by /data to store data
mkfs.xfs /dev/sda1

5. lsblk -f 	or blkid 	--> shows file types under each partition
6. mount -a (only after putting entry in fstab) or mount /dev/dsa1 /data	--> mount fs on /data				note: umount /data
Here we can use mouting options like mount -t <ext4/xfs/nfs etc> -o <default,noacl,ro for read only,noexec for no execut perm etc> 

7. df -h	--> shows mounted disk

Note: partition type 1. standard: cannot extend partition	2. lvm: can be extended
dmidecode -t1	--> shows whether its vmware or physical machine



Day30: Filesystem and mounting in Linux
FS: its way of organising the data in partition. file properties shows which file system we use.  
cat /proc/filesystem 	: shows fs supported by your system
cat /etc/filesystem	: shows auto detected fs types	(ext4 and xfs most widely used)

Journaling: dedicated area in fs where fs chnages are tracked and when system crashes then possibility of fs corruption is less due to journaling + it helps to keeps the data consistent.
ext2: 2nd extended fs. one's most widly used fs but its biggest disadvantage is that takes much time in fs checking + no journaling  + max individual file size be 16GB to 2TB + max ext2 fs size can be from 2TB to 32TB
ext3: similar to ext2 + journaling(3 types: 1.journal(metadata + content stored)	2. ordered: only metadata+ default. metadata jouranl happen only after writing content to disk	3. writeback: only metadata saved + metadata jouranl happen either before or after writing content to disk 
ext4: very big fs + can reduce fs+ journaling + max individual file size be 16GB to 16TB + max ext4 fs size can be 1EB(1024 petabytes where 1PB=1024 TB) + can mount ext3 as ext4 fs + 
xfs: cannot reduce fs + poor performance while deleting large no. of file + default fs of RHEL7 onwards
iso 9960: used to mount CDROM(CD/DVD) iso images 
gfs: always used in cluster fs

tune2fs: used to convert one fs to other (ext2 to ext3 etc)
/etc/fstab	: if need to permanently(servive reboot) mount block device then we make mount point entry in fstab file. 
<UUID=><mount directory><fs type><mode i.e read,write,acl enable etc default usually><0 for dumping i.e backup> <order in which fs check happens,put 0 for dont check fs 1(root fs),2>: here dont provide value >2 otherwise disk chk wil go in emergency.

cat /etc/mtab or mount or cat /proc/mounts	: shows current mount points in system

Note: whatever info you see under /proc these details are updated by kernal.


-----------Converting ext2 to ext3 and ext4---------------
tune2fs -l <parition> | grep feature	--> to see whether journaling supports or not

Note: below partition is mounted as ext2 fs. before converting ext we should unmount fs and then try it.
tune2fs -j <parition>					--> to convert ext2 to ext3 with journaling feature. we cannot jump from ext2 to ext4
tune2fs -O extends,uninit_bg,dir_index <partition>	--> to convert ext3 to ext4
tune2fs -O ^has_journal <partition>			--> to disable journaling
tune2fs -O has_journal <partition>			--> enable again 
 


Day32: Logical volume feature (LVM)
why lvm introduced: 
disk1(8GB)			    Partitions	
/dev/sda----------->	   1(ext2)		    	2(ext3)
		   	/dev/sda1 --> /boot	      /dev/sda2--> /
			   (4GB)			  (4GB)

disk2(50GB)			Total 10GB available
/dev/sdb-----------> 	   1(ext4)			2(xfs)
		    /dev/sdb1 -->/home		/dev/sdb2-->/srv/data
			  (20GB)			(20GB)

Here in standard physical partitions, To extend the partiton task was very hectic and complicated. (backup fs--> unmount--> format existing fs--> recreate partition --> mount --> upload backup + time to do all this etc)
thats why lvm concept was introduced to extend the partition on the go + new feature(snapshot,migrate one LVM under another LVM and merge VG, can attach disk directly to other machine, restore the deleted lvm etc)


disk1	---------> /dev/sda1 ---> pv1 ------------->    Volume group1	 ---------> LVM1(ext4)
/dev/sda	   /dev/sda2 ---> pv2-------------->		VG1			/home
								^        ----------> LVM2(xfs)
								^			/src/data
disk2  ----------> /dev/sdb1 ---> pv3---------------------------^
/dev/sdb	   /dev/sdb2 ---> pv4-------------->     Volume Group2	   -----------> LVM3 (ext4)
								VG2			/apps
								^
disk3 ----------> /dev/sdc1 ---> pv5 ---------------------------^
/dev/sdc		    (physical voumes created with physical partitions)

Note: We need physical volume to create LVM

1. add disk manually 
for x in `/sys/class/scsi_host/` ; do echo "------$x scanned----" echo "---" > /sys/class/scsi_host/$x/scan/ ; done

2. fdisk -l 
3. fdisk /dev/sda1
n --> p -->1-->  2048 -->press enter for default(full) size--> enter --> t --> L--> select 8e for LVM --> enter

4. partprobe
5. lsblk
above has created physical partition
4. pvs	: shows physical volumes available
5. pvdisplay	: for detailed physical volume info
6. pvcreate <partition>
7. vgs		: shows volume group available
8. vgdisplay	: for detailed vg info
9. vgcreate <vg name> <pv1> <pv2> etc
10. lvs or lvdisplay	: to see lvm  info
11. lvcreate -L <logical> 3G -n<new> <lvm name> <VG name>

Mount the directory on LVM
12. mkfs.xfs or mkfx.ext4 <lvm partition name> 	[example: mkfs.ext4 /dev/mapper/LinuxVG-LinuxLV   or /dev/LinuxVG/LinuxLV]
13. mount /dev/LinuxVG/LinuxLV /data
14. df -h 
15. put entry into fstab to make it permanent




--------Resizing LVM-------------
lvextend -L <total size after extend or only extended size with +sign> <partition>
lvextend -L +2000M /dev/LinuxVG/LinuxLV <-r optional>

df -h 	: will not show extended size mount we have to perform below command to make it
resize2fs <partition>				Note: we dont want to use resize2fs then use -r in above command
resize2fs /dev/LinuxVG/LinuxLV

Note: If there is no sufficient space available in VG then we can create PV and add it in VG to extend the LV.


reduce lvm: (please take backup before going ahead with this)
1. unmount partition (umount)
2. fsck -f /dev/LinuxVG/LinuxLV 	: to check file system for any errors
3. resize2fs /dev/LinuxVG/LinuxLV <total size after reduction>
4. lvreduce -L <total size after reduction> /dev/LinuxVG/LinuxLV 

-----LVM snapshot-------------
snapshot is the point in time copy of data. used it for temporary backup.
Note: in the newer systems we can directly create volume group without executing pvcreate command. vgcreate will create pv first and then add that to volume group.
lvcreate -L <size> -s(snapshot) -n(for name) partition

lvconvert --merge <snapshot lcoation[/dev/system/snap] --> restore the snapshot

lvchange -an partition 	--> to deactivate lvm
lvchange -ay partition	--> to activate it again 
mount partition <dir>

Note: modified changes in fs gets captured in snapshot so make sure you provide max value to snapshot while creating it. otherwise whenever snashot utilize % become 100 then snapshot gets corrupt.
grep Snapshot /var/log/messages --> shows snapshot corrupted 

lvextend +<size> <snapshot loca>	--> to extend the snalshot size. to avoid snapshot corrupt issue.
lvremove <snapshot location> 		--> to remove corrupted snapshot


----------Restore mistakenly removed LVM-----------
Supposed you mistakenly removed diff lvm than expected then following way you can recover that:
lvremove parititon	[lvremove /dev/LinuxVG/LinuxLV ]
ls /etc/lvm/archive	--> all changes happen for lvm are available at this position

vgcfgrestore <vg name> --test -f archive_file	: to test the restoration
vgcfgrestore LinuxVG	--test -f /etc/lvm/archive/Linux_VG_00002*.vg 

lvs				: shows restored lvm but its state will be inactive. lvscan used to see lvm status
lvchange -ay partition		: to activate lvm
mount partiton dir
df -h

Note: Before lvm restoration, dir should be unmounted. 
 


Day36: Merging and splitting Volume Groups
We have created 2 lvms in 2 separate Volume Groups.
while creating lvm we have used -l because we are not giving total lvm size. we use <extends> to create lvm in linux. defaults extents is 4MB in linux.
lvcreate -l 1000 -n <lvmname> <vgname>		--> here 1000 X 4MB extents we are creating which is 4GB LVM. this means in lvm we can divide lvm in 4,4MB area.


lvcreate -l 1000 -n lv1 vg1			--> we are creating 2 lvms on 2 diff volume groups.
lvcreate -l 1000 -n lv2 vg2

lvs
mkfs.ext4 /dev/vg1/lv1				--> formating fs to mount to dir
mkfs.xfs /dev/vg2/lv2


mkdir /test1
mkdir /test2

mount /dev/vg1/lv1 /test1
mount /dev/vg2/lv2 /test2

---here if we want to merge 2 VG then we need to unmount lvm of both VG.
umount /test1
umount /test2

after unmounting, you stil see lvm are still in active state. so we need to deactive the lvm which we need to merge with another lvm.
lvscan		--> to see lvm status

vgchange  -an vg2	--> to deactivate lvm2 of vg2
lvscan 	
vgmerge vg1 vg2		--> vgmerge vg1<with whom you want to merge> vg2<which vg you want to merge>
vgs			--> shows only one vg now
vgchange -ay vg2	--> to actvate lvm2 of vg2	or you can also activate using lvm command lvchange -ay /dev/vg2/lv2

now we can mount the directories again which we unmounted before
mount /dev/vg1/lv1	/test1
mount /dev/vg1/lv2	/test2



--------Splitting the vg into multiple vg
In above example, we have lvm1 and lvm2 part of vg1 only. we can split vg1 into vg1 and vg2.
1. unmount /test1 and /test2
umount /test1
umount /test2

2. deactivate the vg1 which we have to split
vgchange -an vg1

3. vgsplit vg1<which we need to split> vg2<new vg> /dev/sda2 <physical volume>
4. vgs
5. vgscan	--> to see status
6. activate the vgs
vgchange -ay vg1 vg2

7. mount /test1 and /test2
mount /dev/vg1/lvm1 /test1
mount /dev/vg2/lvm2 /test2



Day37: Migrating physical volume and LVM from one disk to other on the go
We are moving lvm1 from disk1 to disk2. Consider that you have lvm1 configured under vg1 (disk1). if we have to move lvm1(Vg1-disk1) to disk2 then we should create lvm partition + physical volume under it.
lsblk
sda					disk
 --> sda1				part
       ----> dataVG-dataLV		/data
sdb					disk
 --> sdb1				part

Moving dataVG-dataLV to sdb1 partition
1. pvcreate /dev/sdb1			--> creating physical volume
2. vgextend dataVG /dev/sdb1		---> to extend the Volume Group with physical volume where we want to move disk lvm
3. dmsetup deps /dev/dataVG/dataLV	--> to check lvm1 dependancy, if has any then it can trigger an issue while moving to disk2
4. pvmove -n <lvmname> <source pv> <target pv>
pvmove -n dataLV /dev/sda1 /dev/sdb1			--> moving data from physical volume sda1 to sdb1
5. vgreduce <vgname> <pv name which we need to reduce>
vgreduce dataVG /dev/sda1				--> bcz we have moved data from /dev/sda1 to sdb1


--------Migrating lvm data disk from one machine to another------
1. deativate the volume group(vg)
vgchange -an <vg name>	--> vgchange -an Volgrp
2. export the vg			--> after export if you run lvscan or lvs it should not show you VolGrp in result. 
vgexport Volgrp
3. powerof machine
init 0
4. add above exported disk to new machine
5. scan the vg or pv using pvscan or execute below command
for x in '/sys/class/scsi_host/' ; do echo "-------$x Scanned-----" echo "--->/sys/class/scsi_host/$x/scan/" ; done
6. you can see vg in exported mode so import it first
vgimport VolGrp
7. after importing you will see x option from vgs has been removed. but vg still in deactivate state.
vgchange -ay VolGrp
8. mount exported lvm and access 
mount /dev/VolGrp/LogLVM /data


Day39: Setup thin provisioning volumes in LVM 
Thin provisioning is the concept through which we are using storage space effectively.You can manage the storage pool(LVM) of free spaces called a Thin pool which can
be allocated to number of devices when needed by an application instead of extending the storage pool(VG).

VG	--> volume group is created by deviding the multiple 4MB extents in storage spaces. VG will create 4MB physical extents by default if we not provide physical extend space using -s option. 
vgcreate -s 32M thin_vg /dev/sdb1
lvcreate -L 15G --thinpool tp_thinpool thin_vg		--> we are cerating LVM only just adding --thinpool to make it.

Now we will create 3 LVM of 5G to use the pool
lvcreate -V 5G --thin -n thinpool_clien1 thin_vg/tp_thinpool
lvcreate -V 5G --thin -n thinpool_client2 thin_vg/tp_thinpool
lvcreate -V 5G --thin -n thinpool_client3 thin_vg/tp_thinpool

mount the dir on above created thin provisioned lvms
mkdir -p /mnt/client1 /mnt/client2 /mnt/client3

mkfs.ext4 /dev/thin_vg/thinpool_client1 && mkfs.ext4 /dev/thin_vg/thinpool_client2 && mkfs.ext4 /dev/thin_vg/thinpool_client3
mount /dev/thin_vg/thinpool_client1 /mnt/client1 && mount /dev/thin_vg/thinpool_client2 /mnt/client2 && mount /dev/thin_vg/thinpool_client3 /mnt/client3

dd if=/dev/zero of=/mnt/client1/text.txt bs=1024M count=4 	--> create 4GB dump data

lvcreate -V 5G --thin -n thinpool_client4 thin_vg/tp_thinpool 	--> over-provisioning. we are creating 4th LVM with 5GB space. If its not --thin pool then it will throw error as vg does not have enough memory. In thinpool system will allocates unused memory from other LVM's to lvm4. But here we have to keep monitoring the vg_pool memory threshold.
if vg_pool 100% occupied then lvm will get corrupt.

lvextend -V +15G /dev/thin_vg/tp_thinpool	--> extend thin pool with 15GB more. but to make sure VG has enough memory before adding it. otherwise create pv on disk and add it to vg.

	

Day40: Manage multiple LVM disk using striping I/O
LVM striping	--> Its one of LVM feature which will write on multiple disks instead of constant write on single disk. 
benefits: (disk performance increases + increase disk life + reduce disk fillup issues etc) 

disk1		partition	physical volume
/dev/sda--> /dev/sda1	---> 	pv1	-----------⌄	
	70 I/O					   ⌄
						___⌄__________
disk2					       |             |
/dev/sdb---> /dev/sdb1	---> 	pv2  ------->  |Volume Group |	---> LVM (striping I/O) ---> mount dir
         70 I/O				       |_____________|	
						   ^
disk3						   ^
/dev/sdc --> /dev/sdc1 ----> 	pv3   -------------^
         70 I/O


we consider that we have volume group created with 4 PV(1GB each) in it. 
lvcreate -L 900M -n lv_striping -i4 striping_vg			--> -i4 used to create 4 striping lvm

lvdisplay striping_vg/lv_striping -m			--> see striping lvms using -m option. default striping size is 64 KB

lvcreate -L 1G -i3 -I 256 -n lv_striping2 striping_vg /dev/sda1 /dev/sdb1 /dev/sdc1  		--> here I used to set striping size + which 3PV's should be used for striping.
 


Day41: Logical Volume Manager(LVM) commands
cd /etc/lvm -->found below directories
archive --> vg metadata changes are stored here. using this we can restore deleted lvm
backup  --> stores backup of lvm
cache  --> chached lvm content
profile --> like user profile files, lvm profile files are stored here.
lvm.conf --> used to conigure lvm related configurations. 

/var/lock/lvm  --> files which are used to prevent lvm fs corruption. 

pvck /dev/sba1  --> used to check physical volume consistancy
pvchange -an /dev/sda1   --> used to change lvm attributes. like activate, disable pv etc

vgrename/lvrename oldname  newname	--> to rename vg/lv
lvs -a -o +devices		--> used to lvm details alonhg with devices 


To remove partition --> 
1. unmount directory
2. lvremove /dev/old_vg1/old_lv1
3. vgremove old_vg1
4. pvremove /dev/sda1
5. fdisk /dev/sda --> d(delete)

 
pv attributes:
pvs --> shows 3 dash (---). first is(a-> allocated, u-> unallocated,--- means not used etc)
pvchange -x n /dev/sda1    --> lvs command will show u-- in attributes. here n means no. 


vg attributes:
r,w --> read, write
z   --> resizable
x   --> exported
p   --> partial 

vgcreate options:
-l --> max logical volume
-p --> max physical volume
-s --> physical extent size(default 4MB)
-A --> autoBackup

lvcreate options:
m --> mirrored
M --> mirrored without intial sync
o --> origin
p --> pvmove
s --> snapshot
S --> invalid snapshot
i --> mirror image
I --> mirror image without sync
- --> simple volume



Day42: Create and Manage Swap(file type) Space
Swap space is a virtual space on hard disk which is used as substitute for physical memory and can be used when real RAM fills up and more space is needed. 
1. fdisk /dev/sda
2. n --> p --> 1--> 2048 --> 3G -->w --> t --> L --> select 82 for swap file type --> enter
3. partprobe
4. lsblk -l
5. mkswap /dev/sda1
6. swapon /dev/sda1
7. lsblk --> will show /dev/sda1 as swap fs type
8. cat /proc/swaps  or free -m or top	--> to check swap space 
9. add entry in /etc/fstab to servive the reboot. 

In above example, we have created swap on physical partition but if we need to extend swap then there will be issue. 
so better to make swap on lvm

1. fdisk /dev/sdb
2. n --> p --> 2048 --> 3G -->w --> t --> L --> select 82 for swap file type --> enter
3. partprobe
4. lsblk -l
5. pvcreate /dev/sdb1
6. vgcreate vg /dev/sdb1
7. lvcreate -L 3G -n swap2 vg 					--> lvextend -L +4G /dev/vg/swap2 (to extend swap lvm by 4G)
8. mkswap /dev/sdb1
9. swapon /dev/sdb1
10. lsblk --> will show /dev/sdb1 as swap fs type
11. cat /proc/swaps  or free -m or top	--> to check swap space 
12. add entry in /etc/fstab to servive the reboot. 

Note: never reduce swap space if its on same /root fs lvm

  
----Swap usage and its working, swappiness-------------
Swapping is the process to copy chunks of memory(pages) from RAM to predefined space in hard disk. this is also called paging.   
Total virtual memory in system = RAM size + Swap space

why swapping:
1. when we need more physical memory than existing RAM --> swaps out less utilized pages and gives memry to current application.
2. Most of the applications use RAM for initialization and after that they dont use RAM. so system can move these application in swap space and use memory for new applications. 

disadvantage:
1. its slows the performance of system. RAM--> speed in ns 		Hard Disk --> speed in ms

vmstat  	--> to check pages in and out details. make sure sysstat package is installed 
swappiness	--> is the parameter(range 0-100) intro after RHEL6 to tweak swapping configuration(how freq swapping shd happen etc). RHEL6,7 -> default value is 60 and RHEL8 --> default value is 30
cat /proc/vm/sys/swappiness 	--> to see default value. to inc swap utilization num shd be higher. for less swapping --> less number

echo 50 > /proc/vm/sys/swappiness	--> use to change default swap value temporarily.   
vi /etc/sysctl.conf			--> vm.swappiness=10	--> set permanently 


----use file as swap space-----
we can create file in /root fs and use it as swap space
1. dd if=/dev/zero of=/swapfile bs=1024 count=1048576
or
fallocate -l 1G /swapfile					--> create empty file in root (ideally we should create at location with high memory)

2. chmod 600 /swapfile			--> only root can read file
3. mkswap /swapfile			--> format /swapfile as swap fs type
4. swapon /swapfile -v			--> to enable swap
5. free -m or cat /proc/swaps
6. vi /etc/fstab:
/swapfile	swap	swap	defaults	0 0
    

-----remove swapfile-------
1. erase swap entry from /etc/fstab
2. swapoff /swapfile -v
3. free -h or swapon --show
4. rm -f /swapfile


-------How to use file as virtual hard disk----------
stress	--> used to impose load on system. totally 4 types of load (CPU,RAM,I/O,DISK)
we need to install stress package first. to install stress package we use extra package repo(epel-release) and then install stress.
dnf install -y epel-release 
dnf -y install stress

stress --cpu 4 --timeout 20
stress -m 1 --vm-bytes 4G			--> based on swappiness parameter we can see after a stress load how swap space is being used when RAM is about to get full. 
 

--use file as virtual hard disk----
1. dd if=/dev/zero of=VHD.img bs=1M count=1200		--> 1GB file we are creating
2. mkfs -t ext4 VHD.img
3. blkid
4. mkdir /testdata
5. mount -t auto -o loop VHD.img /testdata		--> if you dont know options you can only write mount -a
6. put entry in fstab
VHD.img /testdata	ext4	default 0 0		--> never mention UUID in fstab for virtual hard disk. always put full location


umount /testdata + delete VHD.img 	---> to unmount virtual hard disk


Day45: RAID and RAID levels(RAID 0)
RAID --> redundant array of independent drives. Its technology used to increase performance and reliability of data storage. RAID system consist of 2 or more drives working together in parallel.
RAID 0 ---> striping (increased performance + no overhead + no fault tolerent) --> ideal for no critical data storage + higher performance requirement
RAID 1 --> mirroring 
RAID 5 --> striping with parity
RAID 6 --> striping with double parity
RAID 10  --> combining striping and mirroring 


Create RAID partitions:(mdadm)
1. fdisk /dev/sda
n--> p--> 1--> 2048 --> 2G --> enter --> w--> t--> L--> fd(RAID file type) --> enter
n--> p--> 2--> 2048 --> 2G --> enter --> w--> t--> L--> fd(RAID file type) --> enter
2. partprobe /dev/sda1 /dev/sdb1
3. cat /proc/mdstat	--> to see if any RAID disk configured
4. mdadm -C(create) /dev/md0 -l(level) 0 -n(no.) 2 /dev/sda1 /dev/sdb1			--> We can also use raw disk to create RAID
5. lsblk 		--> show you RAID partition
6. mdadm -D /dev/md0	--> print detailed RAID info 
7. mkfs.ext4 /dev/md0	--> format RAID partition
8. mkdir /testRAID
9. mount /dev/md0 /testRAID
10. put entry in fstab
/dev/md0	/testRAID	ext4	defaults 0 0


1. unmount dir
2. mdadm -S /dev/md0	--> to stop RAID



-------Create and Manage RAID1-----------
1. fdisk /dev/sda 	+ fdisk /dev/sdb  + fdisk /dev/sdc
n--> p--> 1 --> 2048 --> 2G --> enter --> w--> t--> L--> fd(RAID file type) --> enter
n--> p--> 2 --> 2048 --> 2G --> enter --> w--> t--> L--> fd(RAID file type) --> enter
n--> p--> 3 --> 2048 --> 2G --> enter --> w--> t--> L--> fd(RAID file type) --> enter

2. partprobe /dev/sda1  /dev/sdb1 /dev/sdc1
3. cat /proc/mdstat	--> to see if any RAID disk configured
4. mdadm -C(create) /dev/md0 -l(level) 1 -n(no.) 3 /dev/sda1 /dev/sdb1	/dev/sdc1		--> We can also use raw disk to create RAID
5. lsblk 		--> show you RAID partition
6. mdadm -D /dev/md0	--> print detailed RAID info 
7. mkfs.ext4 /dev/md0	--> format RAID partition
8. mkdir /testRAID
9. mount /dev/md0 /testRAID
10. put entry in fstab
/dev/md0	/testRAID	ext4	defaults 0 0

1. mdadm /dev/md0 -f /dev/sda1 		--> to make the disk faulty
2. unmount /testRAID
3. mdadm /dev/dm0 -r /dev/sda1		--> to remove disk from RAID1 
4. mdadm /dev/md0 -a /dev/sdc1		--> to add new disk to RAID
5. mount /dev/md0 /testRAID


--------Create and Manage RAID5-------
min 3 disks + max 16 disks used in RAID5 + here dedicated disk used for parity checksum(used for error detection and error correction)
fast read transactions + litle slow write + 1 disk failure can withstand(if using 3 disks) --> advantages
complex technology + data can loss if >1 disks failed at same time --> disadvantage
RAID2 + RAID3 + RAID7 --> rarely used

RAID file capacity is always = number of disks used for stripping but not for parity
mdadm -c /dev/md0 -l 5 -n 3 /dev/sda /dev/sdb /dev/sdc 	--> using raw disks to create RAID5 partition
mkfs.ext4 /dev/md0
mkdir /raid5
mount /dev/md0 /raid5
mdadm -D /dev/md0  or cat /proc/mdstat

mdadm /dev/md0 -f /dev/sda	--> to make disk falty
mdadm /dev/md0 -r /dev/sda	--> remove faulty disk
mdadm /dev/md0 -a /dev/sdc	---> add new disk to RAID5



-------Create and Manage RAID6----------
min4 disks + stripping with double parity(dedicated disk is used for parity and that parity backup is saved on other disk) 
if 2 drive fail even withstand(is using 4 disks) + efficient storage + safe data is concern then use RAID6 --> preffered over RAID5
20% slower than RAID5

same steps as above

-----Create and Manage RAID1+0-----------
if one drive fails then rebuilt time is fast as you just have to copy data from mirror disk to new disk --> advantage
half of drive goes into mirroring so comparing with RAID5/RAID6, this is an expensive way of redundancy --> disadvantage

stripping --> happen at upper level and Mirroring -> happens at lower levels
Say we have 4 disks used in RAID10 then there will be 2 sets(SetA(1-1 disk) and SetB(1-1 disk).



Day50: Disk quota management for users and groups in ext4 fs
Disk quota management concept is used to set limits on how much disk space or how many inodes one can use. helps to efficiently use file storage. 
Quota policy:
soft limit : gets warning before full limit used 
hard limit : can't use after this limit
grace period: additional time given to user or grp to use space or inodes

you need to first check quota packages are installed or not:
rpm -qa quota or yum list installed quota
 
3 types of quota can be specified:
1. how much of block space can use
2. how many files one can create by specifying inode value
3. both

1. create partition and mount dir
vi /etc/fstab
/dev/sda1 	/quotadir	ext4	default	0 0
2. mount -a			--> mount quotadir on /dev/sda1
3. mount  grep quota		--> to see whether quota enable on disk or not,we have not enabled so wont show anything.
4. vi /etc/fstab
/dev/sda1 	/quotadir	ext4	default,usrquota,grpquota,prjquota	0 0
5. mount -o remount /quotadir			--> remount 
6. mount  grep quota		--> will show you quota enabled on dir
7. quotacheck -cug /quotadir	--> to create quota files for user and groups, which can be used to set quota limits for user and grps
8. quotaon /quotadir		--> enable quota
edquota	<username>		--> to specify user quota
edquota	-g <grpname>		--> to specify quota for grp
9.quota <username>		--> check quota for users

edquota -T <user> or -g <groupname>	--> default is 7 days. to set grace period for user or grp --> make sure you make quotaon /quotadir after this. else if made in on earlier then makde off, specify grace period an dmake it on.


-----xfs_quota expert utility to manage quota on xfs fs---------------
xfs_quota -x(expert) -c(commandline) report /quotadir			--> shows quota specified on /quotadir
xfs_quota -x -c 'limit bsoft=  bhard=  <username>' /dir			--> set block quota limits for user on /dir
xfs_quota -x -c 'limit isoft= ihard= <usr>' /dir			--> set inode quota limits for user on dir
xfs_quora -x -c 'report bih' /dir					--> to see block and inode quota in human readable format

xfs_quota -x -c 'limit bsoft=  bhard=  <username>' /dir  -c 'limit isoft= ihard= <usr>' /dir		--> set block or inode limit quota in single cmnd


------prjquota used to implement quota limit on dir------------
echo projectname:ID >/etc/prjid
xfs_quota -x -c 'project -s projectname' /dir				--> enable project quota
xfs_quota -x -c 'limit -p bhard= bsoft= prjname' /dir			--> set quota limit on project
xfs_quota -x -c "state -p" /dir						--> to see project quota
xfs_quota -x -c "timer -p<project> -b<block> 10days" /dir		--> reduce grace period using timer on project dir
xfs_quota -x -c "off/disable/enable -pugv" /dir				--> disable/enable quota for project,user and group v-verbose. use off for permanent disable.



Day52: Check and repair FS
fsck,e2fsck(ext fs), xfs_repair(xfs fs)	--> used to check and repair fs.fsck is wrapper on e2fsck. e2fsck was used to chk ext2 fs but later extended to ext3,4.
rpm -qa | grep utils-linux*		--> package resposible for fsck commands. rpm -qf "which fsck" 	--> tells you pcg for fsck commands

Note: fs should not be mounted to check fs. below options are used with fsck
-f	: to forcefully check even disk is clean
-v	: verbose
-a	: to fix if errors any
-n	: dont repair error
-A	: to check all fs in system in order specified in fstab
-R	: exclude root fs



Day53: Virtual data optimizer(VDO) volume
its block virtualization technique + provided data de-duplication and compression facility at block level + can also provide thin provisioned volumes using VDO.
yum list installed kmod-kvdo*				--> need this package for VDO
yum install kmod-kvdo vdo -y				--> install if not available

systemctl start vdo					--> start vdo service to create thin prvisoned volumes
vdo create --name=vdo1  --device=/dev/sda  --vdoLogicalSize=300G		--> create VDO
vdostats -hu						--> shows vdo details
pvcreate /dev/mapper/vdo1				--> created pv
vgcreate vdovg1 /dev/mapper/vdo1			--> created vg of 300GB where pv is of 10GB only

lvcreate -L 50G -n vdolv1 vdovg1			--> create lv 
mkfs.ext4 -k /dev/vdovg1/vdolv1				--> format lv
mount -o discard /dev/vdovg1/vdolv1/ /testvdo		--> used discard option to discard unused blocks from partition.
		


Day54: stratis filesystem (RHEL8 exclusive feature)
default xfs fs use it + can take snapshot + thin provisioning + pool based storage mgmt + fs and storage monitoring we can do in stratis fs
2 statis packages are needed: stratisd --> deomon services used to start stratis services 	stratis-cli --> manage stratis using cli

yum install -y stratisd stratis-cli 		--> if not installed
systemctl start stratisd			--> start and enable stratisd
systemctl enable --now stratisd

lsblk -f					--> to see block devices with fs types
wipefs -a(all) /dev/sdb				--> we can wipe all fs if there exist any on /dev/sdb
stratis pool create stratis_pool1 /dev/sdb (multiple disks)	--> create stratis pool from existing drives 
stratis pool list				--> to list available pools 

stratis fs create stratis_pool1 filesystem-1	--> create fs on stratis pool by formating it
stratis fs list <poolname>			--> show stratis fs

mount /dev/stratis/stratis_pool1/filesystem-1	/data		--> mount stratis fs
vi /etc/fstab:
/dev/stratis/stratis_pool1/filesystem-1		/data
mount -a							--> mount startis fs

stratis fs destory <poolname> <fs-name>				--> to destroy fs from pool
stratis pool add-data <pool name> <disk>			--> to add disk to pool [stratis pool add-data stratis-pool1 /dev/sdb]


stratis fs snapshot stratis_pool1 filesystem-1 mysnapshot1	--> create snapshot from filsystem-1 as mysnapshot1
mount /dev/stratis/stratis-pool1/mysnapshot1	/data		--> to restore file system

rm /dev/stratis/stratis_pool1/mysnapshot			---> to remove snapshot

stratis pool destroy stratis_pool1				---> to destroy the startis pool

 

Day55: Set up disk encryption usng LUKS(utility) in Linux (like BitLocker in windows)
LUKS --> linux unified key setup. used to encrypt the data on disk. 
dnf list installed | grep cryptsetup			--> checking LUKS utility package installed or not. if not then install it

cryptsetup luksFormat 	/dev/sdb			--> formatiing /dev/sdb disk for encrypting it.
cryptsetup luksOpen	/dev/sdb <name of fs on /dev/sdb>	 --> name can be anythng like myfiles etc
cryptsetup status myfiles				--> to check fs status

mkdir /data
mkfs.ext4 /dev/mapper/myfiles

mount /dev/mapper/myfiles	/data			--> mount encrypted disk

---to permanently mount encrypted fs-----
dd if=/dev/urandom of=/temp/crypt_file bs=4096 count = 1			--> creating key file which can be used to encrypt disk. provide password
chmod 600 /tmp/crypt_file

mv /tmp/crypt_file /etc/

cryptsetup luksAddKey	/dev/sdb  /etc/crypt_file			--> define key should be used on which disk to encrypt. 
vi /etc/crypttab							--> file used to mount crypted disk permanently
<name of fs>	<disk>		<key file>
myfile		/dev/sdb	/etc/crypt_file				

vi /etc/fstab
/dev/mapper/myfiles	/data	ext4 default 0 0

mount -a


cryptsetup kulsClose myfiles					--> close encrypted disk
cryptsetup luksRemoveKey	/dev/sdb			--> remove key from disk
cryptsetup luksRemove myfiles					--> remove encrypted fs 
cryptsetup luksChangeKey	/dev/sdb			--> if want to change key which is used to encrypt disk




Day56: RHEL8 Booting process
Booting --> the process of copying os files from hard disk(/boot parition) to RAM sequencially and allowing us to use system  and other os components. 

BIOS 	--> When we start machine, singal flows in motherboard. BIOS prg in chip(CMOS battery) executes POST operation. 
 ⌄
 ⌄
POST  --> power on self test. it checks whether all the attached compoents working or not. and gives control back to BIOS
 ⌄
BIOS 	--> when it gets the POST result as successful then it executes MBR by searching in boot devices (HDD,LAN,CD/DVD,USB etc).
 ⌄		 if there is any h/w issue then system fails.  
 ⌄
MBR	--> Master boot record stored in 1st sector of booting devices.(512byes) primary boot loader information stored in 440 byes of code. its not a main boot loader.    
 ⌄		rather main boot loader sector info stored here. (primary boot loader points to GRUB2 i.e main boot loader)
 ⌄
GRUB2	--> Grand unified loader(v2).  GRUB2 loads its conf. from /boot/grub2/grub.conf file + then provides option to select kernal from boot menu to boot machin 
 ⌄	    then loads selected/default VMLinuz kernal img from /boot/vmlinuz-4.18* + then extract contents of initramfs img frm /boot/initramfs-4.18*
 ⌄		(loads kernal into RAM)
	   /boot/grub2/grub.conf --> this contains info related to grub timeout,default kernal, default run level etc but never edit file directly
Kernal
 ⌄
--> Kernal(VMLinuz) find drivers in initramfs for all h/w intialization/ after this it executes the init process
H/W initialization
 ⌄
 ⌄
/sbin/init execution	--> Kernal executes /sbin/init from initramfs which will start 1st process having PID-1 + in RHEL8 init has been replaced with systemd
	/sbin/init has soft link to ../lib/systemd/system  + its the process which keeps running until system up and stops at last.
 ⌄
initrd.target execution	--> with the help of initramfs systemd executes all units for the initrd.target + In RHEL8 runlevel called as targets. 
 (total 7 targets) + this includes mounting the root fs on disk at /sysroot dir for temp 
 ⌄
Switches root fs	--> Kernal root fs switch from initramfs root(/sysroot) to system root fs(/)
 ⌄
 ⌄
systemd looks for default target  --> system reads the file(/lib/systemd/system/*target) linked by /etc/systemd/system/deafult.target to determine default target(run level)
		systemctl set-deafult <target> --> used to set default run level
 ⌄
1. /lib/systemd/system/runlevel0.target --> poweroff.target
2. /lib/systemd/system/runlevel1.target --> rescue.target
3. /lib/systemd/system/runlevel2.target --> multi-user.target
4. /lib/systemd/system/runlevel3.target --> multi-user.target
5. /lib/systemd/system/runlevel4.target --> multi-user.target
6. /lib/systemd/system/runlevel5.target --> graphical.target
7. /lib/systemd/system/runlevel6.target --> reboot.target
 ⌄
 ⌄
Start other services and OS components 		--> system target file defines the services that system starts



Day57:  Set or Change default run level
1. /lib/systemd/system/runlevel0.target --> poweroff.target		--> shut down + power off 
2. /lib/systemd/system/runlevel1.target --> rescue.target		--> single user mode + without GUI, network
3. /lib/systemd/system/runlevel2.target --> multi-user.target		--> without GUI,n/w
4. /lib/systemd/system/runlevel3.target --> multi-user.target		--> Without GUI but n/w
5. /lib/systemd/system/runlevel4.target --> multi-user.target		--> only for research use only
6. /lib/systemd/system/runlevel5.target --> graphical.target		--> with n/w
7. /lib/systemd/system/runlevel6.target --> reboot.target		--> reboot

runlevel --> command to see runlevel or who -r
systemctl get-default		--> get current permanent default target
cat /lib/systemd/system/default-target			--> shows current target
init <no>			--> imeediatly change run level. it has no impact on default run level


----Resolve kernal panic error------------
Kernal panic error --> due to initramfs files corrupt or deleted 

ls /boot		--> shows kernal files
/etc/grub.d or /etc/default/grub 	--> used to update grub configuration 
grub2-mkconfig		--> after updating above files we run this to make changes in grub confguration  

init 6 or systemctl reboot 		--> reboot machine

-----If we get kernal panic error due to initramfs file corrupt ot deletion-----
1. use grub menu to login through rescue  mode
2. cd /boot 	--> to check initramfs file deleted or corrupted
3. uname -r	--> to check os version
4. dracut -v <initramfs-paste above result.img> <above result>	--> to create initramfs file use -f to override in case corrupt
or 
mkinitrd -v --force initramfs-(uname-r-result).img (uname-r-result) 	--> to regenerate intiramfs files
5. reboot machine


----If grub.conf deleted------
In this case we can't see grub menu to login so follow below steps to fix it.
1. boot os with img file which we have used to install os
2. select troubleshoot option
3. continue (to boot machine using /mnt/systroot)
4. get the shell option
chroot /mnt/sysimage				--> we use chrooting to chnage in os files
grub2-install <device i.e /dev/sda>		--> to install grub2 directory
grub2-mkconfig -o /boot/grub2/grub.conf		--> to generate grub.conf
touch /.autorelabel				--> relabel selinux context
exit


-----Recover VMLinuz files--------------
If VMLinuz file got corrupted or deleted from /boot then follow below steps to recover
1. login to system using grub menu rescue option
2. cd /boot
3. reinstall VMLinuz package 		--> cd /os-img/baseOS/packages/kernel-core-4*
dnf -y reinstall kernel-core-4*.rpm
4. reboot machine


----If both VMLinuz and rescue VMLinuz deleted-------
1. boot through iso image
2. select troubleshoot option
3. select 2nd option centos system
4. select continue (/mnt/sysimage)
5. cd /mnt/install/baseOS/packages/
6. reinstall VMLinuz package 		--> cd /os-img/baseOS/packages/kernel-core-4*
rpm -ivh --root=/mnt/sysimage --replacepkgs kernal-core-4*
7. touch /mnt/sysimage/.autorelabel



--change grub timeout---
vi /etc/default/grub
change timeout to 25 sec
grub2-mkconfig -o /boot/grub2/grub.cfg
init 6



-----Cleanup /boot directory-------
dnf/yum update			--> to update the repo
dnf/yum remove <old kernal>
rm -f <kernal pkg + initrafs file from /boot dir>



Day62: Schedule future jobs using AT
AT 	: used for non repeatative jobs to schedule in future. one time jobs
crontab : used to schedule repeatativ jobs

rpm -q at or yum list installed at		--> to check at pckg installed or not
systemctl status atd.service			--> to check at deamon running

at <time>	--> to schedule job at perticular time. [at now +1 min]
at command or script > file or terminal		--> which will run on above scheduled time. can get terminal info by executing w command 

atq 	or at -l 		--> to list scheduled jobs
at -c <job no>			--> to see jobs details
ls /var/spool/at		--> shows scheduled filed, we can chnage these files to make changes in scheduled cmmand

tail /var/log/cron		--> to see cron jobs logs
atrm <job no>			--> to remove job from at queue

---scheudle jobs on diff times----
at noon +2 min/hours/days
at 7PM +60 days		or at 7PM +2 months
at 00 AM 08/01/2023				--> MMDDYY
at 9:00 AM -f script.sh	> /dev/pts/0		--> print script output on terminal 
at 01 AM -M					--> mail the output. use -m to mail if command failed
at -t 202307120130				-- at -t yyyymmddhhmm 


----------crontabs-------------
powerful utility to schedule non + repeatative jobs 
rpm -q crontabs				--> to check crontab pakge
systemctl status crond.service		--> make sure cron daemon is running 

* * * * * 		--> 1st (*): minute(0-59)	2nd: hour(0-23)		3rd: day of month(1-31)		4th: month(1-12)	5th: day of week(0-6) 0-Sunday
crontab -e		--> edit crontab press i
37 9 * * * echo "Shantayya is smart guy" > /dev/pts/0  
@reboot echo "Shantayya is smart guy" > /dev/pts/0		--> use @ to specify when it should execute

crontab -l 		--> shows cron jobs available based on username. 
crontab -l -u <username>	--> must have sudo access to list other usrs cron jobs
ls /etc/cron.*		--> shows cron dir in which jobs enries happen

cat /etc/cron.deny	--> we can limit users to schedule jobs by makeing user entries in this file.

ls /etc/anacrontab	--> this file is used to schedule jobs using anacron utility on machine which dont run 24X7
crontab -r		--> to remove cron jobs for self account. append -u <username> to remove cron jobs for other users.

------few cron entries------
*/2 * * * * 		--> every 2 min
* */2 * * * 		--> every 2 hrs
0 2 * * *  		--> daily at 2am (*--> means every)
0 5,17 * * * 		--> daily twice at 5AM and 5PM
0 1 1 1,5,8 *		--> only in Jan,May and Aug
0 17 * * 0,5 		--> every sunday and friday. 
0 2 1-7 * * [ `date + \%u` = 7]	&& cmnd --> 1st sunday of every month. 1-7 represents 1st week

* * * * *
* * * * *  sleep 30; 		--> every 30 sec

use ; to schedule multiple tasks
@yearly			--> every year
@monthly 		--> every month
@weekly, @daily, @reboot 

crontab -l > backupfile.txt 			--> take crontab backup
crontab backupfile.txt				--> restore cron jobs

 

Day66: Resource monitoring, management and troubleshooting (CPU,N/W,RAM,STORAGE)
---cpu----
top, free -g, free -s 3 --> to update result every 3 sec
watch -d<delay> -n<no.> 4<sec> cmnd		--> to repeat command every 4 sec. [watch -d -n 4 free -g]
mpstat			--> shows cpu utilization. -P ALL --> for each core utilization

---RAM----
lsof 		--> list of open files. 
lsof -p <pid>	--> to see open files by pid
lsof -i :port_no	--> to list files opened on port number
lsof -u <username>	--> list files with username 


----storage---
iostat		--> used to check input output details. for this to work system should have sysstat package. 
chroot	--> its creates an env(shell) through which we can access root fs directories. 



Day67: package management 
.deb	: extension for debian based packages. --> dpkg, aptitude, apt-get --> comands used to install packages. 
.rpm	: extension for rhel based packages. ---> rpm,yum, dnf	--> utility used to install packages. 

repo	: collection of software and its documentation at central place. 


---debin pkg managemnt-----
dpkg -l		--> shows list of packages installed on machine
dpkg -S rsync	--> to see files installed as part of rsync pkg
dpkg -i httpd	--> to install pkg. -r --> to remove it

Note: only issue with dpkg utility is user have to manually keep track of package dependacies.

apt-get	update/upgrade	--> update pkgs + upgrade makes further enhancement in pkg version plus functionality.
ls /var/cache/apt/archive	--> location where packages are downloaded.
apt-get search rsync		--> search pkg in downloads dir
apt-get install rsync		--> install rsync pkg. remove --> for un install  purge	--> to remove pkg with its conf file.

ls -rt /etc/apt/sources.list	--> contains online repostory urls
add-apt-repository	<url>	--> to add new online repo
or
apt-key add <url> 	

apt-get install alien		--> alien pkg used to convert rpm to deb pkg. Note: but necessary that converted pkg will work. 
alien --to-deb <rpm pkg name> 


---fedora pkg management-----
rpm -qa	| grep samba		--> query all pkg with name samba
-qi				--> query installed : used to see deatailed info of pkg
-i 				--> to install pkg
-e				--> to erase pkg
-Uvh				--> upgrade pkg. v-verbose h-hash(completion %)

ls /var/lib/rpm			--> keeps track of installed pkg(metadata)
rpm2cpio pkg | cpio -t		--> to list archive file containts

Note: issue with rpm utility is that it cannot solve dependancy by itself. 

dnf(RHEL8): advanced version of yum + faster + consumes less memory than yum + written in python 
yum --> to fix dependancy issue in rpm. 

dnf list pkg		--> to search pkg 
dnf list installed	--> installed pkges 
dnf install/remove pkg	--> to install or remove pkg
dnf update/upgrade
dnf grouplist		--> to list groups of pkgs
dnf groupinstall "grouppkg name"	--> install pkg in groups

ls /etc/yum.repos.d/		--> contains repos(dir with .repo ext) having online repo urls


---install any tool on linux using source code---
wget <tool tar ball url>
tar xvf <tool tar bal> 
cd <tool>
./configure  	--> to configure the tool according to env
make 	    	--> to compile tool
make install	--> to install compiled tool



Day68: Configure local YUM/DNF repository
dnf config-manager --add-repo=file:///localrepo/BaseOS/		--> configure repo locally . --add-repo=<path/url>

yum repolist all		--> to see repo list
--install epel repo---
epel : extra pkg enterprise linux
wget <epel repo url> 
dnf install <epel pkg>

createrepo	-->  used to create repo dir from scratch where repodata dir will create accordng to machine

----repo file contents----
name=
metadata_expire=-1	--> -1 means never
gpgcheck=1		--> to check all packages authenticity. to disable-0 
enabled=1		--> to enable repository. 0-disable
baseurl=file:///localrepo/BaseOs/		--> repo path or url
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release


----create repo manually-----
create local repo manullay
1. cd /etc/yum.repos.d
2. vi local.repo 	
name=BaseOS
metadata_expire=-1	--> -1 means never
gpgcheck=1		--> to check all packages authenticity. to disable-0 
enabled=1		--> to enable repository. 0-disable
baseurl=file:///localrepo/BaseOs/		--> repo path or url
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release
3. dnf repolist all		--> shows local available repo




Day70: Network Management
interfaces:
ens160	: bridged network adaptor
lo	: loopback address specified in NIC card.
virbr0	: used to create further virtual network

Network modes:
Host-only	: VM will be assigned one IP. its accessible only on mahcine where vm running. not by other machine.
NAT		: just like home network with wirelss router. vm wil be assigned in separate subnet. 
bridged		: VM will be in the same network as your host. if your host IP is 172.16.120.45 then your vm wil be like 172.16.120.50. it can be accessed by all computers in host n/w.

mode		VM -> Host	Host-> VM	VM <-> VM	VM-> LAN/NET	NET/LAN --> VM
host-only	+		+		+		-		-		
bridged		+		+		+		+		+
NAT	 	+		Port forward	-		+		port forward

nmcli dev status		--> shows available n/w adaptor status
nmcli con show		--> shows connected adaptors

ip addr or ip a or ifconfig		--> to see the Ip details of n/w adaptors.

/etc/sysconfig/network-scripts	: contains adaptor files(added automatically when you add new adaptor connection). below are few files propeties
BOOTPROTO=dhcp/None
ONBOOT=YES

nmcli add con type ethernet con-name <con name> <adaptr name>		--> when you add new adaptor. we have to make it active by this command. IP will be assign by DHCP
nmcli connecton down/up <adaptor name>  or ifdown/ifup <adaptr name> 			--> to bring adaptor in connected/disconnect state 


nmcli con mod <con-name> connection.autoconnect yes/no			--> to auto connect or not. you can also update adaptor file and add ONBOOT=YES/NO 
nmcli con mod <con-name> connection.permissions user:<, separted username> 	--> to provide user permisison to modify nmcli settings.

nmcli con reload		--> reload all connections
nmcli con delete <con-name>	--> to remove adaptor device from machine


nmtui		--> also works like nmcli. however its graphical interface to make changes
open /etc/sysconfig/network-scripts/<adaptor files> 		--> to make adaptor changes.


------assign static IPv4/IPv6 address on machine-----------
nmcli add con type ethernet con-name <con-name> ifname <adaptor name> ip4 <IP> gw4 <gateway ip>	--> to assig IP statucally to any adaptor

nmcli connection modify <con name> +ipv4.addresss <Ip> +ipv4.dns <dns>		--> to add multiple IP to existng conn  add (-ipv4) to remove 

hostnamectl set-hostname <new hostname>		--> to change hostname




--------NIC Teaming(Link aggregation)/Network bonding-------------
Link aggregation(combining more than 2 NIC cards) refers to verious methods of aggregating multiple network connections in parallel in order to increase throughput beyond what a single connnection could sustain.
and to provide redundancy in case of link fail. 

NIC Teaming also called as load balancing failover(LBFO), bandwidth aggregation, traffic failover and so on.
Terminologies:
Teamd	: nic teaming daemon that uses the libteam library to communicate with team devices vie linux kernal.
Teamctl : utility allows users to control teamd instance.  You can check and change the port status as well as switch between active and backup states.
runner(mode)	: units of code written in JSON and used for implementation of NIC teaming. (exmaple of runner mode: round robin,load balancing,active backup, boradcast)

Note: we can have upto 32 NIC in one server.

1. add 2 NIC adaptor in machine
2. nmcli dev status				--> shows adaptors in machine
3. nmcli add connection type team con-name team0 ifname team0 config '{"runner":{"name":"activebackup"}}'		--> create NIC teaming 
4. nmcli con show			--> shows connections in system
5. nmcli connection modify team0 ipv4.addresses 192.168.227.440/24 ipv4.dns 8.8.8.8 connection.autoconnect yes ipv4.method manual	--> assigning IP to team
6. nmcli add connection type team-slave con-name team0-part1 ifname  ens224 master team0     --> adding 1st salve to NIC teaming 
7. nmcli add connection type team-slave con-name team0-part2 ifname  ens225 master team0	    --> adding 2nd slave to NIC teaming 
8. nmcli connection reload			--> reload added configurations
9. nmcli connection up team0/team0-part1/team0-part2


 
Day73: What is routing and Manage routing table 
routing(layer3) is the process of selecting path for traffic in network. 
1. static routing: manual entries. (disadvantage: admin should have topology knowladge)
2. default routing : send packets to next hop( no matter to which n/w packet belongs)
3. dynamic routing: adjustment of the route according to current route in routing table. (-ve: consume more bandwidth + less secure than static)

netstat -rn	or route -n	--> to see routing table
ip route add <ip/24> via <gateway/next hop ip> dev ens160		---> add new entry to rout table. use del to delete route entry

cd /etc/sysconfig/network-scripts
vi route-<adaptername>							---> to service reboot when you add entries to route table 
<destination ip> via <gateway Ip>						/pro/net/route		is the file responsible for routing table

nmcli connection reload
systemctl restart NetworkManager



Day74: Network Sniffing and ssh configuration 
The process of monitoring all the data packets passing through network connections is called sniffing. 
wireshark	--> utility used to monitor connections
tcpdump tcp port 22			--> to check packets passing over tcp port 22


rpm -qa | grep openssh			--> utility used for ssh connection
systemctl status sshd			--> sshd daemon should always be running to work ssh

cat /etc/hosts				--> If want to use server name instead of IP then put entry in /etc/hosts

ssh username@IP command			--> execute command on server without logging into it. 

--password less auth---
vi server.txt
server1
server2
server3

for i in 'cat server.txt'; do ssh root@$i ssh-copy-id -i ~/.ssh/id_rsa.pub root@$i done;

-------Welcome banner---------
1. pre-login	: when we do ssh, banner shows before we put password and enter into server.
vi /etc/ssh/banner.txt
Welcome to Server1

vi /etc/ssh/sshd_config
uncomment banner line
banner <banner file path>		--> banner /etc/ssh/banner.txt 

systemctl restart sshd

2. post-login
edit /etc/motd	file for post login banner


----disable root login through ssh------
cat /etc/ssh/sshd_config
permitRootLogin  yes/no				--> make it No to disable root login to enhanve security


-------change default ssh port--------- 
To avoid unahtourised access or secure it from attacker.

1.  update port number in /etc/ssh/sshd_config file
port 5152
2. update ssh port entry in firewall
firewall-cmd --list-all				--> list firewall settings 
firewall --permanent --add-port=5152/tcp	--> add ssh port in firwall 
3. to relload firewall settings
firewal-cmd --reload
4. update se linux entries
semanage port -l | grep ssh				--> to see selinux ssh port 
cat /etc/ssh/sshd_config | grep semanage	--> to check selinux syntax to add port number
semanage port -a -t ssh_port_t -p tcp 5152 
5. systemctl restart sshd
6. test ssh with 5152 port 
ssh user@server -p 5152


---Allow/Deny seleted user/group to login via ssh------
allow	: if we put selected user then only that perticular user can login through ssh. other users(including root) will be denied. 
vi /etc/ssh/sshd_config
AllowUsers user1 user2			--> allow only user1 and user2
DenyUsers  user3 user3			--> selected deny

systemctl restart sshd

AllowGroups <grp name>			--> use group allow or deny if have to allow or deny multiple users.
DenyGroups  <grp name>	


-----Allow/Deny access from selected IP/Network through ssh--------
TCP wrappers	: works only in RHEL 7

/etc/hosts*	--> below 2 files are used to allow or deny access from perticular IP 
hosts.allow
hosts.deny

vi /etc/hosts.deny
<service>:<IP>
sshd:192.168.0.198		--> cannot ssh from this IP. [sshd 192.168.0.0/24 --> to deny whole network subnet]

systemctl restart sshd		--> restart denied service	

Note: If we denied whole network and we also wants to provide access to single machine from that network then put that entry in hosts.allow.
hosts.allow file overrides hosts.deny file entries

TCP wrappers does not work in RHEL8

----RHEL8 uses sshd_service to allow/deny access from IP---
vi /etc/ssh/sshd_config
DenyUsers *@192.164.0.198			--> deny all users frm this IP. [DenyUsers *@192.164.0.*]	--> deny all users from whole nmetwork

Note: DenyUsers entry overrides AlloUsers enrty in RHEL 8


--------Configure ssh login alert notification-----------
dnf install -y mailx sendmail			--> these 2 utilities are imp to send mail alerts
systemctl enable/start sendmail

cd <enter>					--> goto user home directory for which user we have to configure mail service 
vi .bashrc
echo ALERT - ROOT login on shell "$HOSTNAME" on `date` `who` | mail -s "Alert: ROOT login detected" <mailID>

source .bashrc
mail						--> to check mail inbox
tail /var/log/maillog				--> to see logs



Day82: Reset forgotten root password
1. select first option in grub menu and press e			[in RHEL9 select rescue option]
2. select line where linux has been written and go to end of line. replace rhgb quit with rd.break enforcing =0
3. ctl+x
4. mount -o remount,rw /sysroot		--> remounting sysroot from read only fs to rw mode. (single user mode)
5. chroot /sysroot
6. passwd 				--> chnage root password
7. touch /.autorelabel
8. exit					--> exit chroot env
9. exit and enter to boot system	--> exit maintenance mode 


-------Set or remove GRUB password------------
If you have forgotten the root password, But if you can see GRUB options then one can easly recover root password. 
what if attacker change root password if one get access to BOOT menu? so to increase security of system. 

1. it prevents access to single user mode
2. unauthorized access to system 
3. prevents access to GRUB console

----set GRUB password
1. cat /etc/grub.d/10_linux | grep gnu-linux
2. remove --unresticted from class= line
sed -i "/^CLASS=/s/ --unrestricted//" /etc/grub.d/10_linux 
3. ls /boot/grub2/				--> if we dont have grub password set then we wont see user.cfg file here
4. grub2-setpassword				--> set grub password
5. ls /boot/grub2/				--> can see user.cfg file
6. grub2-mkconfig -o /boot/grub2/grub.cfg	--> let kernal know grub changes


---remove grub password
1. add --unrestricted in  gnu-linux line in /etc/grub.d/10_linux file
2. remove user.cfg from /boot/grub2/
3. grub2-mkconfig -o /etc/grub.d/10_linux			--> make grub changes permanent

or 
vi /etc/grub2.cfg
comment for loop of password_pbk
shutdown -r now

Note: If you forgot both grub + root password then boot with iso image and do chrooting to reset grub password. 


Day84: Automate backup using rsync and cron
yum list installed rsync
dnf install -y rsync
rsycn -v source/* destination/ --progress		--> to backup source to destination 
rsycn -av -e ssh source/* root@IP:/destination/		--> -a archive -e remote shell	copy backup on remote machine
  


Day85: Firewall
Firewall is the process used to manage and monitor in-coming and out-poing traffic from network. 
	       RHEL6				RHEL7						RHEL8
		GUI			GUI			CLI			GUI		CLI	
	 	⌄			 ⌄			 ⌄			 ⌄		 ⌄
	 	⌄			 ⌄		 	 ⌄			 ⌄		 ⌄
	    system-config-firewall	firwall-config	     firewall-cmd	firewall-config    firewall-cmd (package)
	       ⌄					⌄					⌄
	       ⌄					⌄					⌄
	iptables(daemon service)		firewalld(service)			firewalld(service)
					⌄							⌄
					⌄							⌄
				     iptables						    NFTABLES(packet filter mechanism)
					⌄							⌄
					⌄							⌄
			   kernal(netfilter module)					kernal(netfilter module)

commenly used ports:
SSH	: 22
Telnet 	: 23
FTP/SFTP: 20/21
SMTP	: 25
DNS	: 53
HTTP(s)	: 80/443
DHCP	: 67/68
POP3	: 110

dnf install -y firewalld firewall-config
systemctl start/stop/enable firewalld

firewall-cmd --state			--> shows firewallc0md status
firewall-cmd --get-default-zone		--> get default zone being used 

firewall-cmd --list-all			--> shows firewall configuration 
firewall-cmd --get-services		--> shows default services firewall knows
firewall-cmd --zone=public(if deafult then not needed) --permanent --add-service=http (this service should be there in firewall services list)	--> add new service to firewall. --remove-service(for removal)

firewall-cmd --reload			--> eload firewall settings
firewall-cmd --zone=home  --change-interface=ens160	--> change the zone an interface belongs to 
firewall-cmd --get-active-zones		--> list active zones

ls /usr/lib/firewalld/		--> contains network scripts
ls /etc/firewalld/		--> contains all dir copies from /ur/lib/firewalld. firewall.conf --> file used to change firewall conf globally

cd /etc/firewalld/services/	
vi <service_name>.xml		--> to add new services to firewall-list but to add that services we need to run --add-srvice=<service_name> command

firewall-cmd --permanent --add-port=80/tcp	--> add service by port number. --remove-port(to remove port)
firewall-cmd -permanent --add-forward-port=port=80:proto=tcp:toport=8080 		--> port forwarding

firewall-cmd --permanent --add-masquerade	--> to enable masquerading servive
firewall-cmd --permanent --add-forward-port=port=443:proto=tcp:toport=443:toaddr=192.168.16.12		--> masqeurading(only work on ipv4)

Note: basic difference between iptables and firewall-cmd is you have to stop existing firewall rules before you add new one. otherwise firewall-cmd --reload will wipe out existing firewall rules and only accept newly added. 
but this is not the case in RHEL7/8

firewall-cmd --permanent --add-rich-rule 'rule family="ipv4" source address="192.168.16.16" port port=22 protocol=tcp reject'	--> reject traffic from IP

firewall-cmd --permanent --add-rich-rule 'rule family="ipv4" source address="192.168.16.16" service name=ssh or port port=23 limit value=1/m accept'	--> accept telnet only from perticular IP with limit connection per min.

firewall-cmd --permanent --add-rich-rule 'rule protocol value=icmp reject'		--> reject ping from all sources.

icmp --> network later protocol used by n/w devices to diagnose network connectivity issue. (ping or telnet) 
firewall-cmd --permanent --add-icmp-block=echo-request			--> to disable icmp acknowladgement. ping will not work 

firewall-cmd --enable-panic		--> block all network traffic in case of emergency
 

Note: Make sure to reload firewall-cmd after every fiewall configuration.



Day87: Security enhanced linux (SELINUX)
added security layer works on mandatory access control(MAC) mechanism in linux kernal to make linux very secured and different from other os. 
selinux implement MAC mechanism(as per predefine rules. enforced or no)in kernal, checking for allowed permissions after std discretionary access control(DAC) are checked. by default enabled in fedora. 
SeLinux security = Role based access control(RBCA) + type enforcement(TE) + multilevel security(MLS)
terminologies in selinux:
objects		--> dir or files
subjects	--> process or user

total 3 modes of selinux:
1. enforced	: Selinux denies access based on policy defined. 
2. permissive	: does not deny access but denail access are logged in logs for actions that would have been denied if running in enfored mode.  
3. Disable	: Only DAC rules are used. 

getenforce	--> used to check selinux mode
setenforce 0/1	--> 0-permissive	1-enforced

SELinux context(or label): process and files are labelled with an selinux context that contains additional info like 
selinux user,role,type and securty level etc. when running selinux all this info used to make acl dicisions. 

SELinux user:role:type:level	--> syntax
user	: its user identity mapped to selinux roles to apply ACL
role	: attribute part of RBAC. domains --> roles --> selinux users.
type	: type enforcement decides domain for processes.
level	: attribute of MLS (sensitivity(s0-s15):category-set(c0-c1023))

ls -Z filename			--> -z shows selinux settings
ls -dZ dirname			--> shows selinux settings on dir
ps -eZ pid			--> shows process selinux info
id -Z				--> user selinux info. by default unconfined
sestatus			--> shows selinux status
semanage login -l		--> shows local user mapping with selinux user info

tail /var/log/audit/audit.log		--> selinux logs(auditd.services runs at background) 

selinux policy:
1. Targeted policy: default selinux policy used in fedora. whe used, processes that are targeted run in confined domain else run in unconfined domain.
subjects running in unconfined domain cannot allocate writable memory and execute it to avoid vulnerability attack. 

confined processes: almost all the processes that listen on network like sshd,ftp is confined in fedora. (avoid attacks) confine processes run in its own
domain. Even if attacker gets control of confined process then damage will be minimul bcz confined process cannot access other domains. 

unconfined processes: If unconfined process gets compromized then attacker can access any other process running in system.
processes started by systemd or which does not use network run in unconfined domain. 
unconfined_service_t	--> if process started by init
kernal_t		--> process started by kernal
unconfined_t		--> started by linux user

chcon -t <service type> <service/object>	--> change context temporarily. [chcon -t bin_t httpd] making httpd to run as unconfined process. 
restorecon service/object			--> restore context of server [restorecon httpd]


confined user: by default selinux users are unconfined. However we can confined them due to security restrictions. confined users are restricted by selinux
rules explicitely defined in current security policy. 
seinfo -u/-r		--> shows selinux users + roles. setools-console utility requires(audit selinux logs). 

useradd -Z selinux_role username	--> by default users are unconfined. but can make them confined using this command. 
semanage login -m -s user_u -r s0 __default__		--> modifying __default__ selinux user as confined. so whenever new local user created in linux it wil be confined under __default__ selinux user.
semanage login -m -s unconfined_u -r s0 __default__	--> make all new users unconfined. 

semanage boolean -l		--> check selinux user permissions bollean status. through this booleans only we can restrict permissions. 
setsebool -P ssh_sysadm_login on/off	--> provide ssh access to sysadmin if on(confined user) -P: permanently 


rpm -qi policycoreutils			--> utility required for basic basic operations of selinux systems
rpm -qi selinux-policy			--> this is base package for SELinux reference policy
rpm -qi selinux-policy-targeted 	--> SeLinux reference policy targeted base module
rpm -qi libselinux			--> provides api for selinux applications 
rpm -qi libselinux-utils		--> contains utilities (avcstat,getenforce,getsebool etc)
rpm -qi libselinux-python		--> required python bindings for selinux applications
rpm -qi selinux-policy-devel		--> provides custom selinux policy and policy modules.
rpm -qi selinux-policy-mls		--> to use multilevel security
rpm -qi settroubleshoot-server		--> used to troubleshoot selinux issues. 
rpm -qi policycoreutils-python		--> semanage,audit2allow,chcat etc
rpm -qi policycoreutils-gui		--> if want to manage selinux through gui

2. minimum	: modification of targeted policy. only selected processes are potected.
3. mls		: multi-level security protection. use sensitivity and category pair values to define confidentiality level. If we use mls then even root
can't have all the access. it can only access things defined in selinux for root user. 

cat /etc/selinux/config		--> file contains policy info and its modes. to change selinu mode permanently 

chcon -t <service type> <service/object>		--> temporaily change context of service or object
semanage fcontext -a -t samba_share_t /etc/file		--> make entry in selinux policy. but implement post restart
restorecon -v /etc/file					--> make changes permanently by implementing policy doc

semanage fcontext -a -t samba_share_t "/web(/.*)?" 	--> change selinux type of all files specified under dir. use -d to delete selinux context
restorecon -v /web/*					--> relabel selinux context. 

semanage port -l			--> list ports managed by selinux
semanage port -a -t ssh_port_t	-p tcp 5555	--> to add 5555 as ssh port in selinux. use -d instead of -a to delete rule in selinux
touch /.autorelabel			--> it reset selinux changes made though chcon and service reboot  

cp file /dir				--> change seliux context of file to seliux context of dir
cp --preserve=context file /dir		--> preserves selinux context of file even after copying under dir.


---enable selinux mls-----
1. dnf install -y settools-console
2. edit /etc/selinux/config
make mode=permissive 		--> from enforcing
3. touch "F" >>/.autorelabel	--> to reset selinux changes
4. reboot
5. getenforce to see the change 



Day88: SSH Port forwarding or tunneling 
SSH port forwarding allows you to forward otherwise insecure tcp traffic inside secure ssh tunnel from source to destination.(can be used for FTP,HTTP,SMTP,
TELNET etc)
provide encryption + authentication + must create new ssh for tunneling 
1. local port forwarding: create local port that is connected to remote service.
2. remote		: forward a port on remote server on internet to local port. executing command from remote machine for local 
3. dynamic 		: used tp bypass firewall. used SOCKS protocol proxy port


--local port forwarding between 2 servers---
webserver: http service running on port 80
local server: ssh -f -N -L localhost:5555:<webserver ip>:80 root@<webserverip> 		--> you can see port forwadring process running on local machine.

---local port forwarding with 3 servers-----
webserver: http service running on port 80
gateway server: 
local server: ssh -f -N -L localhost:5555:<webserver ip>:80 root@<gateway IP>

------local port forwarding with 3 servers using gateway port-----
webserver: http service running on port 80
gateway server: firewall-cmd --permanent --add-port=5555/tcp  + firewall-cmd --reload
local server: ssh -g -f -N :5555:<webserver ip>:80 root@<webserver ip>


--Remote port forwarding between 2 servers---
webserver: http service running on port 80
webserver: ssh -f -N -R localhost:5555:<webserver ip>:80 root@<local server IP>


----Dynamic port forwarding-----
webserver: http service running on port 80 buts blocked by firewall
local machine: ssh -f -N -D localhost:5555:<webserver IP>:80 root@<webserver IP>
	       curl --proxy socks5h://localhost:5555 http://<webserver IP>:80 


Day89:
-----------Shell Scripting-----------------
cat /etc/shells or chsh	-l 		--> shows shell list
chsh	--> enter shell to be used	--> change default shell
echo ''		--> print as it is
echo ""		--> print value 
echo -e "HEll\nShantayya"		--> use -e if want to use \
#!/bin/bash				--> shebang line tells interpreter that which shell we are using 

# 	: comment
$	: to print value of variable
export var=		--> to globally define the variable

----read operator---
read name		--> to take single input from user
read name1 name2 name3 name3	--> take multiple inputs from user
read -p 'Enter user Name' name	--> input cursor stays in same line 
read -sp 'Enter password' pass	--> take silent input

echo "Enter user names"
read -a  names	--> take multiple inputs(space separated) as array

read 
echo "Entered name is $REPLY"		--> If we dont provide any variable with read then value stored in REPLY variable. 

---Passing the argument in script----
system reserve variables used temporarilty to hold value ($1,$2,$3 etc)

vi script.sh 
#!/bin/bash
echo $1 $2 $3 $4

./script.sh hi how are you?

instead of system reserve variabes we can use args array: 
args=("$@")
echo ${args[0]} ${args[1]} ${args[2]} ${args[3]}	or echo $@			--> it will print 4 arguments 

echo $#				--> shows number of arguments passed

---Coditional statement-----
string comparison operator:
[ "$a" == "$b" ]
[ "$a" != "$b" ]
[[ "$a" < "$b" ]] use [[ ]] for <,>,<=,>= string operator.

integer comparsion operator:
[ "$a" -eq/ne/lt/le/gt/ge "$b" ]
("$a" </> "$b")
(( "$a" <= "$b" )) or (( "$a" >= "$b" ))

echo -e "Enter name of file: \c" 	--> -e used in echo to use \ char and -c to keep cursor at same place. 
read num1 num2
if [ $num1 -eq $num2 ]
then
 echo "Num1 is equa t num2"
elif [ $num1 -gt $num2 ]
then
  echo "Num1 greater than num2" 
else
 echo "Num1 less than num2"
fi

----File test operator-------
[ -e $filename ]	--> -e means exists or not. -f means regular ile or not. -d means directory or not, -b means block file or not, -c char file or not. -s empty file or not. 
-r file has read perm or not, -w file has write perm or not, -x file has execute perm or not. 

----Nested If condition-----
echo -e "Enter file name: \c"
read filename
if [ -f $filename ]
then
	if [ -w $filename ]
	then	
		echo "Please enter text here and press ctl + d to exit"
		cat >> $filename
	else
		echo "$filename does not have write access"
	fi
else
	echo "$filename does not exist"
fi


----Logical AND operator-----&&, ||
echo -e "Enter your age: \c"
read age
if [ "$age" -gt 18 ] && [ "$age" -lt 40 ]
then
	echo "Age is valid"
else
	echo "Age is not valid"
fi

echo -e "Enter your age: \c"
read age
if [ "$age" -le 18 ] || [ "$age" -ge 40 ]
then
	echo "Age is valid"
else
	echo "Age is not valid"
fi


-----Arithmatic operator on integers-----
$((operation)) or $( expr $num1 operator $num2 )  --> to use * with expr use \* [ $( expr $num1 \* $num2 )]
echo "sum is $((2+3))"

----Arithmatic operation on decimal numbers---
bc	--> basic calculator. this utility is required to execute bc command.
echo "2/3" | bc
echo "scale=2;2/3" | bc		--> use scale=number for decimal places
echo "scale=2;sqrt(10)" | bc -l	--> use -l(library) with bc for advanced operation.


Day119: AWK command
awk is mostly used for pattern matching and processing + data transformation. 
syntax:
awk options 'selection_criteria {action}' input_file > output_file

vi employee.txt
Shantayya  Manager  Accounts  50000
Shankar    Manager  Sales     100000
Somnath    Master   Operation 500000
Vir        Head	    Account   1500000

awk '{print}' filename		--> print file details like cat
awk '/Manager/ {print}' employee.txt	--> print nly Managers
awk '{print $1 $4}' employee.txt	--> print 1st and 4th col. or use NF(number of fields) [awk '{print $1,$NF}' employee.txt]
awk '{print NR,$0}' employee.txt	--> use NR to show record numbers $0 for all records
awk 'NR==3, NR==4 {print NR,$0}' employee.txt	--> record 3 to 4
awk 'END {print NR}' employee.txt	--> print last record number. to see hw many lines are there in file. 

use for loop in awk
awk 'BEGIN { for(i=1;i<=6;i++) print "Square of" i, "is", i*i; }' 

awk -F ":" '{print $1}'	/etc/passwd		--> default separator is space in awk.we can use diff separator using -F field.
awk -F "\" '/^\// {print $NF}' /etc/shells	--> print shell names only
awk 'length($0) < 8' /etc/shells		--> print records length less than 8